B_S,
S_W,
B_W,
sig = 1,
lamType,
alpha = 0.05,
ite = 100,
ite2 = 100,
Xtype = design_type,
reportPercent=seq(0, 1, by = 0.2))
result['label1'] = 'OracleLasso'
result['label2'] = as.character(lamType)
result['label3'] = is.infinite(result$logVol)
result['label4'] = design
return(result)
}
res_OracleLasso__combined_signals = rbind(cur_OracleLasso__combined_signals(lamType1, 1, 'Toeplitz'),
cur_OracleLasso__combined_signals(lamType2, 1, 'Toeplitz'),
cur_OracleLasso__combined_signals(lamType1, 2, 'ExpDecay'),
cur_OracleLasso__combined_signals(lamType2, 2, 'ExpDecay'),
cur_OracleLasso__combined_signals(lamType1, 3, 'EquiCor'),
cur_OracleLasso__combined_signals(lamType2, 3, 'EquiCor'))
save(res_OracleLasso__combined_signals,
file='C:/Study/Phd/HonestCI/data/summary/oracleLasso_n500p600_combined.Rdata')
# adaptive
cur_Adaptive__combined_signals = function(lamType, dir, design)
{
result = testAdaptive__combined_singals(N,
P,
S_S,
B_S,
S_W,
B_W,
sig = 1,
lamType = lamType,
alpha = 0.05,
ite = 100,
dir,
reportPercent=seq(0, 1, by = 0.2))
result['label1'] = 'Adaptive'
result['label2'] = as.character(lamType)
result['label3'] = is.infinite(result$logVol)
result['label4'] = design
return(result)
}
resAdaptive__combined_signals = rbind( cur_Adaptive__combined_signals(lamType1, toe_dir, 'Toeplitz'),
cur_Adaptive__combined_signals(lamType2, toe_dir, 'Toeplitz'),
cur_Adaptive__combined_signals(lamType3, toe_dir, 'Toeplitz'),
cur_Adaptive__combined_signals(lamType4, toe_dir, 'Toeplitz'),
cur_Adaptive__combined_signals(lamType1, exp_dir, 'ExpDecay'),
cur_Adaptive__combined_signals(lamType2, exp_dir, 'ExpDecay'),
cur_Adaptive__combined_signals(lamType3, exp_dir, 'ExpDecay'),
cur_Adaptive__combined_signals(lamType4, exp_dir, 'ExpDecay'),
cur_Adaptive__combined_signals(lamType1, equi_dir, 'EquiCor'),
cur_Adaptive__combined_signals(lamType2, equi_dir, 'EquiCor'),
cur_Adaptive__combined_signals(lamType3, equi_dir, 'EquiCor'),
cur_Adaptive__combined_signals(lamType4, equi_dir, 'EquiCor'))
save(resAdaptive__combined_signals,
file='C:/Study/Phd/HonestCI/data/summary/adaptive_n500p600_combined.Rdata')
Rdata_dir = 'C:/Study/Phd/HonestCI/data/summary'
Rdata = list.files(Rdata_dir, '*.Rdata')
for (name in Rdata) {
before = load(file.path(Rdata_dir, name))
assign(name, get(before))
}
save(list = Rdata, file = file.path(Rdata_dir, 'summary.Rdata'))
library(plyr)
?ddply
?aov
install.packages("foreach")
install.packages("foreach")
install.packages("foreach")
install.packages("foreach")
install.packages("foreach")
install.packages("foreach")
install.packages("foreach")
install.packages("foreach", dependencies = T)
install.packages("foreach", dependencies = T)
?latinsquare
?summary
?LSD.test
??LSD.test
?LSD.test
fun = function(delta, n)
{
res = (sqrt(1 + 2 * delta / sqrt(n)) - 1) ^ 2 * n
return(res)
}
?seq
delta = 10
n = seq(0, 100, by = 0.5)
y = fun(delta, n)
plot(n, y)
delta = 1
n = seq(0, 100, by = 0.5)
y = fun(delta, n)
plot(n, y)
delta = 30
n = seq(0, 100, by = 0.5)
y = fun(delta, n)
plot(n, y)
delta = 30
n = seq(0, 1000, by = 1)
y = fun(delta, n)
plot(n, y)
delta = 30
n = seq(0, 10000, by = 1)
y = fun(delta, n)
plot(n, y)
delta = 3
n = seq(0, 10000, by = 1)
y = fun(delta, n)
plot(n, y)
delta = 30
n = seq(0, 10000, by = 1)
y = fun(delta, n)
plot(n, y)
delta = 30
n = seq(0, 100000, by = 10)
y = fun(delta, n)
plot(n, y)
delta = 30
n = seq(0.0001, 100000, by = 10)
y = fun(delta, n)
plot(n, y)
delta = 1
n = seq(0.0001, 100000, by = 10)
y = fun(delta, n)
plot(n, y)
delta = 2
n = seq(0.0001, 100000, by = 10)
y = fun(delta, n)
plot(n, y)
delta = 30
n = seq(0.0001, 100000, by = 10)
y = fun(delta, n)
plot(n, y)
delta = 30
n = seq(0.0001, 10000000, by = 1000)
y = fun(delta, n)
plot(n, y)
length(y)
y[10000]
setwd("C:/Study/Phd/HonestCI/R code/hoffman2/honest CI/n200p800")
# new c(alpah), y ~ N(0, sigma I)
library(glmnet)
library(plyr)
library(LDRTools)
source("data_fun.R")
# Shrink Y towards zero by Stein estimate
SteinToZero = function(Y, df, sig)
{
B = sig^2 * df / L2NormSquare(Y)
mu = (1 - B) * Y
sure = sig^2 * max(1 - B, 0)
return(list(mu = mu, sure = sure))
}
# calculate c(alpha) for Stein. (for squared radius)
quantile_stein = function(mu, df, alpha, sig, iteNum, projection=NULL)
{
n = dim(mu)[1]
if (is.null(projection))
projection = diag(rep(1, n))
z = rep(0, iteNum)
for (i in 1:iteNum)
{
Y_sample = mu + tcrossprod(projection, matrix(rnorm(n, sd = sig), nrow = 1))
res = SteinToZero(Y_sample, df, sig)
z[i] = abs(res$sure - L2NormSquare(res$mu - mu) / df) * sqrt(df) / (sig^2)
}
c = quantile(z, probs = 1 - alpha)
return (c)
}
weak_stein = function(X2, Y2, A, sig, alpha_s, c_alpha_w, upper)
{
n2 = dim(X2)[1]
p = dim(X2)[2]
k = length(A)
# strong signals
if (k == 0)
{
mu_s = 0
r_s = 0
P_perp = diag(rep(1, n2))
} else
{
P_A = B2P(X2[,A])
mu_s = P_A %*% Y2
r_s = sqrt(qchisq(1-alpha_s, df = k) / n2) * sig
P_perp = diag(rep(1, n2)) - P_A
}
# weak signals
stein = SteinToZero(tcrossprod(P_perp, t(Y2)), n2 - k, sig)
r_w = sqrt((n2 - k) / n2 * (c_alpha_w * sig^2 / sqrt(n2 - k) + stein$sure))
mu_w = stein$mu
# update r_s_ratio r_w_ratio if A is not empty
if (k == 0)
{
r_s_volume = 0
r_w_volume = r_w
logVol_volume = n2 * log(r_w_volume)
r_radius = r_w
logVol_radius = n2 * log(r_radius)
} else
{
# by volume
lower = upper / (upper - 1)
c_s = max(lower, min(n2 / k, upper))
c_w = c_s / (c_s - 1)
r_s_volume = r_s * sqrt(c_s)
r_w_volume = r_w * sqrt(c_w)
logVol_volume = k * log(r_s_volume) + (n2 - k) * log(r_w_volume)
# by radius
r_radius = sqrt(r_s^2 + r_w^2)
logVol_radius = n2 * log(r_radius)
}
return(list(r_s_volume = r_s_volume,
r_w_volume = r_w_volume,
logVol_volume = logVol_volume,
r_radius = r_radius,
logVol_radius = logVol_radius,
mu_s = mu_s,
mu_w = mu_w))
}
threshold = function(beta, tau)
{
count = 0
candidates = list()
tau_chosen = list()
for(i in 1:length(tau))
{
A = which(abs(beta) > tau[i])
if (i != 1 && length(A_old) == length(A) && all(A_old == A))
{
next
}
A_old = A
count = count + 1
candidates[[count]] = A
tau_chosen[[count]] = tau[i]
}
return(list(candidates = candidates,
tau_chosen = tau_chosen,
count = count))
}
two_step = function(X1, X2, Y1, Y2, lam1, lam2Coef, s, sig, ratios, alpha, upper, ite)
{
n1 = dim(X1)[1]
n2 = dim(X2)[1]
p = dim(X1)[2]
# stein c(alpha)
mu = matrix(rep(0, n2), ncol = 1)
c_alpha_stein = quantile_stein(mu, n2, alpha / 2, sig, ite)
# candidates
lasso_split = glmnet(X1, Y1, family='gaussian', intercept = F, lambda = lam1)
res_candidate = threshold(as.matrix(lasso_split$beta), lam1 * ratios)
# statistics
res_stein_pool = list()
logVol_volume_stein = rep(0, res_candidate[['count']])
logVol_radius_stein = rep(0, res_candidate[['count']])
# record
for (i in 1:res_candidate[['count']])
{
res_stein = weak_stein(X2, Y2, res_candidate[['candidates']][[i]], sig, alpha / 2, c_alpha_stein, upper)
res_stein_pool[[i]] = res_stein
logVol_volume_stein[i] = res_stein[['logVol_volume']]
logVol_radius_stein[i] = res_stein[['logVol_radius']]
}
i_volume_stein = which.min(logVol_volume_stein)
i_radius_stein = which.min(logVol_radius_stein)
volume_stein = list(r_s = res_stein_pool[[i_volume_stein]][['r_s_volume']],
r_w = res_stein_pool[[i_volume_stein]][['r_w_volume']],
mu_s = res_stein_pool[[i_volume_stein]][['mu_s']],
mu_w = res_stein_pool[[i_volume_stein]][['mu_w']],
logVol = res_stein_pool[[i_volume_stein]][['logVol_volume']],
A = res_candidate[['candidates']][[i_volume_stein]],
k = length(res_candidate[['candidates']][[i_volume_stein]]),
tau = res_candidate[['tau_chosen']][[i_volume_stein]])
radius_stein = list(r_s = res_stein_pool[[i_radius_stein]][['r_radius']],
r_w = res_stein_pool[[i_radius_stein]][['r_radius']],
mu_s = res_stein_pool[[i_radius_stein]][['mu_s']],
mu_w = res_stein_pool[[i_radius_stein]][['mu_w']],
logVol = res_stein_pool[[i_radius_stein]][['logVol_radius']],
A = res_candidate[['candidates']][[i_radius_stein]],
k = length(res_candidate[['candidates']][[i_radius_stein]]),
tau = res_candidate[['tau_chosen']][[i_radius_stein]])
return(list(volume_stein = volume_stein, radius_stein = radius_stein))
}
convert = function(m_list, X2, beta) {
n2 = dim(X2)[1]
p = dim(X2)[2]
if (m_list[['k']] == 0) {
P_perp = diag(rep(1, n2))
part1 = m_list[["mu_w"]] - X2 %*% beta
part2 = P_perp / m_list[["r_w"]]^2
} else
{
P_A = B2P(X2[,m_list[['A']]])
P_perp = diag(rep(1, n2)) - P_A
part1 = m_list[["mu_s"]] + m_list[["mu_w"]] - X2 %*% beta
part2 = P_A / m_list[["r_s"]]^2  + P_perp / m_list[["r_w"]]^2
}
temp = (t(part1) %*% part2 %*% part1)/ n2
return(list(coverage = as.numeric(temp) <= 1,
r_s = m_list[['r_s']],
r_w = m_list[['r_w']],
k = m_list[['k']],
logVol = m_list[['logVol']],
tau = m_list[['tau']]))
}
# ite for computing quantile is set here
two_step_test = function(n, p, sig, alpha, ite, arg)
{
ite_quantile = 100
volume_stein_pool = list()
radius_stein_pool = list()
beta_pool = t(as.matrix(read.table(arg[['beta']])))
Y1_pool = t(as.matrix(read.table(arg[['Y1']])))
Y2_pool = t(as.matrix(read.table(arg[['Y2']])))
if (arg[['lam1Type']] == '1se') {
lam1 = read.table(arg[['1se']])[,1]
}
else if (arg[['lam1Type']] == 'cv') {
lam1 = read.table(arg[['cv']])[,1]
}
else if (arg[['lam1Type']] == 'val') {
lam1 = rep(2 * sqrt(2) * sqrt(log(p) / n), ite)
}
lam2Coef = arg[['lam2Coef']]
s = arg[['s']]
ratios = arg[['ratios']]
upper = arg[['upper']]
#foreach (i = 1:ite, .export = c("SteinToZero", "quantile_stein", "trunate_beta", "quantile_lasso", "weak_stein", "weak_lasso", "threshold", "convert", "two_step", "L2NormSquare", "generateBeta"), .packages = c("glmnet")) %dopar%
for( i in 1:ite)
{
fileX1 = paste(arg[['root']], '/X1/', i, '.txt', sep = "")
fileX2 = paste(arg[['root']], '/X2/', i, '.txt', sep = "")
X1 = as.matrix(read.table(fileX1))
X2 = as.matrix(read.table(fileX2))
beta = beta_pool[, i, drop = F]
Y1 = Y1_pool[, i, drop = F]
Y2 = Y2_pool[, i, drop = F]
# necessary statistics
res = two_step(X1, X2, Y1, Y2, lam1[i], lam2Coef, s, sig, ratios, alpha, upper, ite_quantile)
volume_stein = convert(res[['volume_stein']], X2, beta)
volume_stein_pool[[i]] = volume_stein
radius_stein = convert(res[['radius_stein']], X2, beta)
radius_stein_pool[[i]] = radius_stein
}
volume_stein_df = ldply(volume_stein_pool, data.frame)
radius_stein_df = ldply(radius_stein_pool, data.frame)
return(list(volume_stein_df = volume_stein_df,
radius_stein_df = radius_stein_df))
}
# set the oracle sparsity as the true sparsity in arg[['s']]
two_step_single = function(n, p, svalue, bvalue, sig, lam1Types, alpha, ite, rawDir,
lam2Coef, ratios, upper)
{
arg = list()
volume_stein_list = list()
radius_stein_list = list()
count = 1
for (i in 1:length(lam1Types))
{
for (j in 1:length((svalue)))
{
for (k in 1:length(bvalue))
{
arg[['root']] = rawDir
arg[['beta']] = paste(rawDir, '/beta/', 'beta', '_s', svalue[j], '_b', bvalue[k], '.txt', sep = "")
arg[['Y1']] = paste(rawDir, '/Y1/', 'Y1', '_s', svalue[j], '_b', bvalue[k], '.txt', sep = "")
arg[['Y2']] = paste(rawDir, '/Y2/', 'Y2', '_s', svalue[j], '_b', bvalue[k], '.txt', sep = "")
arg[['lam1Type']] = lam1Types[i]
if (arg[['lam1Type']] == '1se') {
arg[['1se']] = paste(rawDir, '/1se/', '1se', '_s', svalue[j], '_b', bvalue[k], '.txt',
sep = "")
}
else if (arg[['lam1Type']] == 'cv') {
arg[['cv']] = paste(rawDir, '/cv/', 'cv', '_s', svalue[j], '_b', bvalue[k], '.txt',
sep = "")
}
arg[['lam2Coef']] = lam2Coef
arg[['s']] = svalue[j]
arg[['ratios']] = ratios
arg[['upper']] = upper
# calculate necessary statistics
tempRes = two_step_test(n, p, sig, alpha, ite, arg)
volume_stein_df = tempRes$volume_stein_df
radius_stein_df = tempRes$radius_stein_df
volume_stein_df['lam1Type'] = lam1Types[i]
volume_stein_df['s'] = svalue[j]
volume_stein_df['b'] = bvalue[k]
volume_stein_df['method'] = 'twoStepSteinVolume'
radius_stein_df['lam1Type'] = lam1Types[i]
radius_stein_df['s'] = svalue[j]
radius_stein_df['b'] = bvalue[k]
radius_stein_df['method'] = 'twoStepSteinRadius'
volume_stein_list[[count]] = volume_stein_df
radius_stein_list[[count]] = radius_stein_df
count = count + 1
}
}
}
return(list(volume_stein_df = ldply(volume_stein_list),
radius_stein_df = ldply(radius_stein_list)))
}
# set the oracle sparsity as the true sparsity in arg[['s']]
two_step_multiple = function(n, p, s_s, b_s, s_w, b_w, sig, lam1Types, alpha, ite, rawDir,
lam2Coef, ratios, upper)
{
arg = list()
volume_stein_list = list()
radius_stein_list = list()
count = 1
for (i in 1:length(lam1Types))
{
for (j in 1:length((b_s)))
{
for (k in 1:length(b_w))
{
arg[['root']] = rawDir
arg[['beta']] = paste(rawDir, '/beta', '/beta', '_ss', s_s, '_bs', b_s[j], '_sw', s_w,
'_bw', b_w[k], '.txt', sep="")
arg[['Y1']] = paste(rawDir, '/Y1', '/Y1', '_ss', s_s, '_bs', b_s[j], '_sw', s_w,
'_bw', b_w[k], '.txt', sep="")
arg[['Y2']] = paste(rawDir, '/Y2', '/Y2', '_ss', s_s, '_bs', b_s[j], '_sw', s_w,
'_bw', b_w[k], '.txt', sep="")
arg[['lam1Type']] = lam1Types[i]
if (arg[['lam1Type']] == '1se') {
arg[['1se']] = paste(rawDir, '/1se', '/1se', '_ss', s_s, '_bs', b_s[j], '_sw', s_w,
'_bw', b_w[k], '.txt', sep="")
}
else if (arg[['lam1Type']] == 'cv') {
arg[['cv']] = paste(rawDir, '/cv', '/cv', '_ss', s_s, '_bs', b_s[j], '_sw', s_w,
'_bw', b_w[k], '.txt', sep="")
}
arg[['lam2Coef']] = lam2Coef
arg[['s']] = s_s + s_w
arg[['ratios']] = ratios
arg[['upper']] = upper
# calculate necessary statistics
tempRes = two_step_test(n, p, sig, alpha, ite, arg)
volume_stein_df = tempRes$volume_stein_df
radius_stein_df = tempRes$radius_stein_df
volume_stein_df['lam1Type'] = lam1Types[i]
volume_stein_df['bs'] = b_s[j]
volume_stein_df['bw'] = b_w[k]
volume_stein_df['method'] = 'twoStepSteinVolume'
radius_stein_df['lam1Type'] = lam1Types[i]
radius_stein_df['bs'] = b_s[j]
radius_stein_df['bw'] = b_w[k]
radius_stein_df['method'] = 'twoStepSteinRadius'
volume_stein_list[[count]] = volume_stein_df
radius_stein_list[[count]] = radius_stein_df
count = count + 1
}
}
}
return(list(volume_stein_df = ldply(volume_stein_list),
radius_stein_df = ldply(radius_stein_list)))
}
# implementation
library(plyr)
source("data_fun.R")
source("utils.R")
N = 200
P = 800
SVALUE = c(5, 10)
BVALUE = c(0.1, 0.3, 0.5, 0.7, 0.9, 1, 2, 3, 4, 5)
S_S = 5
B_S = c(0.1, 0.3, 0.5, 0.7, 0.9, 1, 2, 3, 4, 5)
S_W = 5
B_W = c(0.1, 0.2)
ITE = 100
NFOLDS = 5
RATIOS = seq(from = 0, to = 4, by = 0.05)
toe_dir = "data/toeplitz"
exp_dir = 'data/exp_decay'
equi_dir = 'data/equi_corr'
lam1Types = c('val', 'cv', '1se')
alpha = 0.05
dir_pool = c(toe_dir, exp_dir, equi_dir)
design = c("toeplitz", "exp. decay", "equal cor.")
RATIOS = seq(from = 0, to = 4, by = 0.05)
UPPER = 10
lam2Coef = 0.5
# two step
volume_stein_single_alpha = list()
radius_stein_single_alpha = list()
volume_stein_multiple_alpha = list()
radius_stein_multiple_alpha = list()
for (i in 1:length(dir_pool)) {
temp = two_step_single(N, P, SVALUE, BVALUE, sig = 1, lam1Types, alpha, ITE, dir_pool[i],
lam2Coef, RATIOS, UPPER)
temp[['volume_stein_df']]['design'] = design[i]
temp[['radius_stein_df']]['design'] = design[i]
volume_stein_single_alpha[[i]] = temp[['volume_stein_df']]
radius_stein_single_alpha[[i]] = temp[['radius_stein_df']]
temp = two_step_multiple(N, P, S_S, B_S, S_W, B_W, sig = 1, lam1Types, alpha, ITE, toe_dir,
lam2Coef, RATIOS, UPPER)
temp[['volume_stein_df']]['design'] = design[i]
temp[['radius_stein_df']]['design'] = design[i]
volume_stein_multiple_alpha[[i]] = temp[['volume_stein_df']]
radius_stein_multiple_alpha[[i]] = temp[['radius_stein_df']]
}
summary_volume_stein_single_alpha = ldply(volume_stein_single_alpha)
summary_radius_stein_single_alpha = ldply(radius_stein_single_alpha)
summary_volume_stein_multiple_alpha = ldply(volume_stein_multiple_alpha)
summary_radius_stein_multiple_alpha = ldply(radius_stein_multiple_alpha)
save_list = c("summary_volume_stein_single_alpha", "summary_radius_stein_single_alpha",
"summary_volume_stein_multiple_alpha", "summary_radius_stein_multiple_alpha")
save(list = save_list, file = 'summary_alpha.Rdata')
