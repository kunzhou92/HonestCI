index = rowSums(expand.grid(index, (0:9) * n))
# generate data
Y_large = mu_large + matrix(sig * rnorm(n * 10), ncol = 1)
index
index = which(sub_grp == 1)
# index = sample(1:n, ceiling(n / 2))
index = rowSums(expand.grid(index, (0:9) * n))
index[1:10]
index[45:54]
length(index)
n
# generate data
row = rep(1:n, 10)
X_large = x[row, ]
mu_large = matrix(y[row], ncol = 1)
# output
tot = 2
stein1 = list()
stein2 = list()
adapt1 = list()
adapt2 = list()
for (i in 1:tot){
index = which(sub_grp == 1)
# index = sample(1:n, ceiling(n / 2))
index = rowSums(expand.grid(index, (0:9) * n))
# generate data
Y_large = mu_large + matrix(sig * rnorm(n * 10), ncol = 1)
X1 = X_large[index, ]
X2 = X_large[-index, ]
Y1 = Y_large[index, ,drop=F]
Y2 = Y_large[-index, ,drop=F]
mu1 = mu_large[index, ,drop=F]
mu2 = mu_large[-index, ,drop=F]
adapt1[[i]] = adaptive_real(X1, X2, Y1, Y2, mu1, mu2, sig)
adapt2[[i]] = adaptive_real(X2, X1, Y2, Y1, mu2, mu1, sig)
stein1[[i]] = two_step_stein_real_data(X1, X2, Y1, Y2, mu1, mu2, sig)
stein2[[i]] = two_step_stein_real_data(X2, X1, Y2, Y1, mu2, mu1, sig)
}
adapt_df1 = ldply(adapt1, data.frame)
adapt_df2 = ldply(adapt2, data.frame)
stein_df1 = ldply(stein1, data.frame)
stein_df2 = ldply(stein2, data.frame)
# a wrap function
two_step_stein_real_data = function(X1, X2, Y1, Y2, mu1, mu2, sig) {
# constants
alpha = 0.05
upper = 10
# lam1 setup
lam1 = cv.glmnet(X1, Y1, intercept = F)$lambda.1se
model = two_step(X1, X2, Y1, Y2, lam1, numCandidate, alpha, upper, ite, sig)$volume_stein
n2 = dim(Y2)[1]
if (model[['k']] == 0)
{
part1 = model[["mu_w"]] - mu2
part2 = diag(rep(1, n2)) / model[["r_w"]]^2
mu_s_norm = 0
mu_w_norm = L2NormSquare(model[['mu_w']]) / n2
diff_s_norm = 0
diff_w_norm = L2NormSquare(model[["mu_w"]] - mu2) / n2
w_norm = L2NormSquare(mu2) / n2
cover_s = NA
cover_w = L2NormSquare(model[["mu_w"]] - mu2) / n2 / model[["r_w"]]^2
r_s_raw = NA
r_w_raw = model[['r_w']]
} else if (model[['k']] >= n2)
{
part1 = model[["mu_s"]] - mu2
part2 = diag(rep(1, n2)) / model[["r_s"]]^2
mu_s_norm = L2NormSquare(model[['mu_s']]) / n2
mu_w_norm = 0
diff_s_norm = L2NormSquare(model[["mu_s"]] - mu2) / n2
diff_w_norm = 0
w_norm = 0
cover_s = L2NormSquare(model[["mu_s"]] - mu2) / n2 / model[["r_s"]]^2
cover_w = NA
r_s_raw = model[["r_s"]]
r_w_raw = NA
} else
{
########################## new #########################
qr_decom = qr(X2[,model[['A']]])
k = qr_decom$rank
Q = qr.Q(qr_decom)
P_A = B2P(Q[,1:k])
#########################################################
P_perp = diag(rep(1, n2)) - P_A
part1 = model[["mu_s"]] + model[["mu_w"]] - mu2
part2 = P_A / model[["r_s"]]^2  + P_perp / model[["r_w"]]^2
mu_s_norm = L2NormSquare(model[['mu_s']]) / n2
mu_w_norm = L2NormSquare(model[['mu_w']]) / n2
diff_s_norm = L2NormSquare(model[["mu_s"]] - P_A %*% mu2) / n2
diff_w_norm = L2NormSquare(model[["mu_w"]] - P_perp %*% mu2) / n2
w_norm = L2NormSquare(P_perp %*% mu2) / n2
lower = upper / (upper - 1)
c_s = max(lower, min(n2 / k, upper))
c_w = c_s / (c_s - 1)
# print(c_s)
# print(c_w)
cover_s = L2NormSquare(model[["mu_s"]] - P_A %*% mu2) / n2 / model[["r_s"]]^2 * c_s
cover_w = L2NormSquare(model[["mu_w"]] - P_perp %*% mu2) / n2 / model[["r_w"]]^2 * c_w
r_s_raw = model[['r_s']] / sqrt(c_s)
r_w_raw = model[['r_w']] / sqrt(c_w)
}
covered = (t(part1) %*% part2 %*% part1)/ n2 <= 1
list(r_s = model[['r_s']], r_w = model[['r_w']], k = model[['k']],
hsigma = model[['hsigma']], logVol = model[['logVol']], coverage = covered,
cover_s = cover_s, cover_w = cover_w,
diff_s_norm = diff_s_norm, diff_w_norm = diff_w_norm,
r_s_raw = r_s_raw, r_w_raw = r_w_raw,
w_norm = w_norm)
}
adaptive_real = function(X1, X2, Y1, Y2, mu1, mu2, sig) {
# constants
alpha = 0.05
# lam1 setup
lam1 = cv.glmnet(X1, Y1, intercept = F)$lambda.1se
adaptive(X1, Y1, X2, Y2, mu2, lam1, sig, alpha)
}
# generate data
row = rep(1:n, 10)
X_large = x[row, ]
mu_large = matrix(y[row], ncol = 1)
# output
tot = 2
stein1 = list()
stein2 = list()
adapt1 = list()
adapt2 = list()
for (i in 1:tot){
index = which(sub_grp == 1)
# index = sample(1:n, ceiling(n / 2))
index = rowSums(expand.grid(index, (0:9) * n))
# generate data
Y_large = mu_large + matrix(sig * rnorm(n * 10), ncol = 1)
X1 = X_large[index, ]
X2 = X_large[-index, ]
Y1 = Y_large[index, ,drop=F]
Y2 = Y_large[-index, ,drop=F]
mu1 = mu_large[index, ,drop=F]
mu2 = mu_large[-index, ,drop=F]
adapt1[[i]] = adaptive_real(X1, X2, Y1, Y2, mu1, mu2, sig)
adapt2[[i]] = adaptive_real(X2, X1, Y2, Y1, mu2, mu1, sig)
stein1[[i]] = two_step_stein_real_data(X1, X2, Y1, Y2, mu1, mu2, sig)
stein2[[i]] = two_step_stein_real_data(X2, X1, Y2, Y1, mu2, mu1, sig)
}
adapt_df1 = ldply(adapt1, data.frame)
adapt_df2 = ldply(adapt2, data.frame)
stein_df1 = ldply(stein1, data.frame)
stein_df2 = ldply(stein2, data.frame)
i
# generate data
row = rep(1:n, 10)
X_large = x[row, ]
mu_large = matrix(y[row], ncol = 1)
# output
tot = 1
stein1 = list()
stein2 = list()
adapt1 = list()
adapt2 = list()
for (i in 1:tot){
index = which(sub_grp == 1)
# index = sample(1:n, ceiling(n / 2))
index = rowSums(expand.grid(index, (0:9) * n))
# generate data
Y_large = mu_large + matrix(sig * rnorm(n * 10), ncol = 1)
X1 = X_large[index, ]
X2 = X_large[-index, ]
Y1 = Y_large[index, ,drop=F]
Y2 = Y_large[-index, ,drop=F]
mu1 = mu_large[index, ,drop=F]
mu2 = mu_large[-index, ,drop=F]
adapt1[[i]] = adaptive_real(X1, X2, Y1, Y2, mu1, mu2, sig)
adapt2[[i]] = adaptive_real(X2, X1, Y2, Y1, mu2, mu1, sig)
stein1[[i]] = two_step_stein_real_data(X1, X2, Y1, Y2, mu1, mu2, sig)
stein2[[i]] = two_step_stein_real_data(X2, X1, Y2, Y1, mu2, mu1, sig)
}
adapt_df1 = ldply(adapt1, data.frame)
adapt_df2 = ldply(adapt2, data.frame)
stein_df1 = ldply(stein1, data.frame)
stein_df2 = ldply(stein2, data.frame)
colMeans(df1, na.rm = T)
colMeans(df2, na.rm = T)
# a wrap function
two_step_stein_real_data = function(X1, X2, Y1, Y2, mu1, mu2, sig) {
# constants
alpha = 0.05
upper = 10
ite = 400
numCandidate = 20
# lam1 setup
lam1 = cv.glmnet(X1, Y1, intercept = F)$lambda.1se
model = two_step(X1, X2, Y1, Y2, lam1, numCandidate, alpha, upper, ite, sig)$volume_stein
n2 = dim(Y2)[1]
if (model[['k']] == 0)
{
part1 = model[["mu_w"]] - mu2
part2 = diag(rep(1, n2)) / model[["r_w"]]^2
mu_s_norm = 0
mu_w_norm = L2NormSquare(model[['mu_w']]) / n2
diff_s_norm = 0
diff_w_norm = L2NormSquare(model[["mu_w"]] - mu2) / n2
w_norm = L2NormSquare(mu2) / n2
cover_s = NA
cover_w = L2NormSquare(model[["mu_w"]] - mu2) / n2 / model[["r_w"]]^2
r_s_raw = NA
r_w_raw = model[['r_w']]
} else if (model[['k']] >= n2)
{
part1 = model[["mu_s"]] - mu2
part2 = diag(rep(1, n2)) / model[["r_s"]]^2
mu_s_norm = L2NormSquare(model[['mu_s']]) / n2
mu_w_norm = 0
diff_s_norm = L2NormSquare(model[["mu_s"]] - mu2) / n2
diff_w_norm = 0
w_norm = 0
cover_s = L2NormSquare(model[["mu_s"]] - mu2) / n2 / model[["r_s"]]^2
cover_w = NA
r_s_raw = model[["r_s"]]
r_w_raw = NA
} else
{
########################## new #########################
qr_decom = qr(X2[,model[['A']]])
k = qr_decom$rank
Q = qr.Q(qr_decom)
P_A = B2P(Q[,1:k])
#########################################################
P_perp = diag(rep(1, n2)) - P_A
part1 = model[["mu_s"]] + model[["mu_w"]] - mu2
part2 = P_A / model[["r_s"]]^2  + P_perp / model[["r_w"]]^2
mu_s_norm = L2NormSquare(model[['mu_s']]) / n2
mu_w_norm = L2NormSquare(model[['mu_w']]) / n2
diff_s_norm = L2NormSquare(model[["mu_s"]] - P_A %*% mu2) / n2
diff_w_norm = L2NormSquare(model[["mu_w"]] - P_perp %*% mu2) / n2
w_norm = L2NormSquare(P_perp %*% mu2) / n2
lower = upper / (upper - 1)
c_s = max(lower, min(n2 / k, upper))
c_w = c_s / (c_s - 1)
# print(c_s)
# print(c_w)
cover_s = L2NormSquare(model[["mu_s"]] - P_A %*% mu2) / n2 / model[["r_s"]]^2 * c_s
cover_w = L2NormSquare(model[["mu_w"]] - P_perp %*% mu2) / n2 / model[["r_w"]]^2 * c_w
r_s_raw = model[['r_s']] / sqrt(c_s)
r_w_raw = model[['r_w']] / sqrt(c_w)
}
covered = (t(part1) %*% part2 %*% part1)/ n2 <= 1
list(r_s = model[['r_s']], r_w = model[['r_w']], k = model[['k']],
hsigma = model[['hsigma']], logVol = model[['logVol']], coverage = covered,
cover_s = cover_s, cover_w = cover_w,
diff_s_norm = diff_s_norm, diff_w_norm = diff_w_norm,
r_s_raw = r_s_raw, r_w_raw = r_w_raw,
w_norm = w_norm)
}
# generate data
rep_int = 5
row = rep(1:n, rep_int)
X_large = x[row, ]
mu_large = matrix(y[row], ncol = 1)
# output
tot = 1
stein1 = list()
stein2 = list()
adapt1 = list()
adapt2 = list()
for (i in 1:tot){
index = which(sub_grp == 1)
# index = sample(1:n, ceiling(n / 2))
index = rowSums(expand.grid(index, (0:(rep_int - 1)) * n))
# generate data
Y_large = mu_large + matrix(sig * rnorm(n * rep_int), ncol = 1)
X1 = X_large[index, ]
X2 = X_large[-index, ]
Y1 = Y_large[index, ,drop=F]
Y2 = Y_large[-index, ,drop=F]
mu1 = mu_large[index, ,drop=F]
mu2 = mu_large[-index, ,drop=F]
adapt1[[i]] = adaptive_real(X1, X2, Y1, Y2, mu1, mu2, sig)
adapt2[[i]] = adaptive_real(X2, X1, Y2, Y1, mu2, mu1, sig)
stein1[[i]] = two_step_stein_real_data(X1, X2, Y1, Y2, mu1, mu2, sig)
stein2[[i]] = two_step_stein_real_data(X2, X1, Y2, Y1, mu2, mu1, sig)
}
adapt_df1 = ldply(adapt1, data.frame)
adapt_df2 = ldply(adapt2, data.frame)
stein_df1 = ldply(stein1, data.frame)
stein_df2 = ldply(stein2, data.frame)
# output
tot = 1
adapt_df1
adapt_df2
stein_df1
stein_df2
# generate data
rep_int = 10
row = rep(1:n, rep_int)
X_large = x[row, ]
mu_large = matrix(y[row], ncol = 1)
# output
tot = 1
stein1 = list()
stein2 = list()
adapt1 = list()
adapt2 = list()
for (i in 1:tot){
index = which(sub_grp == 1)
# index = sample(1:n, ceiling(n / 2))
index = rowSums(expand.grid(index, (0:(rep_int - 1)) * n))
# generate data
Y_large = mu_large + matrix(sig * rnorm(n * rep_int), ncol = 1)
X1 = X_large[index, ]
X2 = X_large[-index, ]
Y1 = Y_large[index, ,drop=F]
Y2 = Y_large[-index, ,drop=F]
mu1 = mu_large[index, ,drop=F]
mu2 = mu_large[-index, ,drop=F]
adapt1[[i]] = adaptive_real(X1, X2, Y1, Y2, mu1, mu2, sig)
adapt2[[i]] = adaptive_real(X2, X1, Y2, Y1, mu2, mu1, sig)
stein1[[i]] = two_step_stein_real_data(X1, X2, Y1, Y2, mu1, mu2, sig)
stein2[[i]] = two_step_stein_real_data(X2, X1, Y2, Y1, mu2, mu1, sig)
}
adapt_df1 = ldply(adapt1, data.frame)
adapt_df2 = ldply(adapt2, data.frame)
stein_df1 = ldply(stein1, data.frame)
stein_df2 = ldply(stein2, data.frame)
# generate data
rep_int = 10
row = rep(1:n, rep_int)
X_large = x[row, ]
mu_large = matrix(y[row], ncol = 1)
# output
tot = 1
stein1 = list()
stein2 = list()
adapt1 = list()
adapt2 = list()
for (i in 1:tot){
index = which(sub_grp == 1)
# index = sample(1:n, ceiling(n / 2))
index = rowSums(expand.grid(index, (0:(rep_int - 1)) * n))
# generate data
Y_large = mu_large + matrix(sig * rnorm(n * rep_int), ncol = 1)
X1 = X_large[index, ]
X2 = X_large[-index, ]
Y1 = Y_large[index, ,drop=F]
Y2 = Y_large[-index, ,drop=F]
mu1 = mu_large[index, ,drop=F]
mu2 = mu_large[-index, ,drop=F]
adapt1[[i]] = adaptive_real(X1, X2, Y1, Y2, mu1, mu2, sig)
adapt2[[i]] = adaptive_real(X2, X1, Y2, Y1, mu2, mu1, sig)
stein1[[i]] = two_step_stein_real_data(X1, X2, Y1, Y2, mu1, mu2, sig)
stein2[[i]] = two_step_stein_real_data(X2, X1, Y2, Y1, mu2, mu1, sig)
}
adapt_df1 = ldply(adapt1, data.frame)
adapt_df2 = ldply(adapt2, data.frame)
stein_df1 = ldply(stein1, data.frame)
stein_df2 = ldply(stein2, data.frame)
44 + 27
ceiling(71 / 2)
setwd("C:/Study/Phd/HonestCI/R code/current development/7 n200p800 against_normality_homogeneity")
library(plyr)
library(hdi)
library(scalreg)
source("data_fun.R")
source("utils.R")
source("adaptive_fun.R")
source("oracle_fun2.R")
source("two_step_fun_real_data.R")
# a wrap function
two_step_stein_real_data = function(X1, X2, Y1, Y2, mu1, mu2, sig) {
# constants
alpha = 0.05
upper = 10
ite = 400
numCandidate = 20
# lam1 setup
lam1 = cv.glmnet(X1, Y1, intercept = F)$lambda.1se
model = two_step(X1, X2, Y1, Y2, lam1, numCandidate, alpha, upper, ite, sig)$volume_stein
n2 = dim(Y2)[1]
if (model[['k']] == 0)
{
part1 = model[["mu_w"]] - mu2
part2 = diag(rep(1, n2)) / model[["r_w"]]^2
mu_s_norm = 0
mu_w_norm = L2NormSquare(model[['mu_w']]) / n2
diff_s_norm = 0
diff_w_norm = L2NormSquare(model[["mu_w"]] - mu2) / n2
w_norm = L2NormSquare(mu2) / n2
cover_s = NA
cover_w = L2NormSquare(model[["mu_w"]] - mu2) / n2 / model[["r_w"]]^2
r_s_raw = NA
r_w_raw = model[['r_w']]
} else if (model[['k']] >= n2)
{
part1 = model[["mu_s"]] - mu2
part2 = diag(rep(1, n2)) / model[["r_s"]]^2
mu_s_norm = L2NormSquare(model[['mu_s']]) / n2
mu_w_norm = 0
diff_s_norm = L2NormSquare(model[["mu_s"]] - mu2) / n2
diff_w_norm = 0
w_norm = 0
cover_s = L2NormSquare(model[["mu_s"]] - mu2) / n2 / model[["r_s"]]^2
cover_w = NA
r_s_raw = model[["r_s"]]
r_w_raw = NA
} else
{
########################## new #########################
qr_decom = qr(X2[,model[['A']]])
k = qr_decom$rank
Q = qr.Q(qr_decom)
P_A = B2P(Q[,1:k])
#########################################################
P_perp = diag(rep(1, n2)) - P_A
part1 = model[["mu_s"]] + model[["mu_w"]] - mu2
part2 = P_A / model[["r_s"]]^2  + P_perp / model[["r_w"]]^2
mu_s_norm = L2NormSquare(model[['mu_s']]) / n2
mu_w_norm = L2NormSquare(model[['mu_w']]) / n2
diff_s_norm = L2NormSquare(model[["mu_s"]] - P_A %*% mu2) / n2
diff_w_norm = L2NormSquare(model[["mu_w"]] - P_perp %*% mu2) / n2
w_norm = L2NormSquare(P_perp %*% mu2) / n2
lower = upper / (upper - 1)
c_s = max(lower, min(n2 / k, upper))
c_w = c_s / (c_s - 1)
# print(c_s)
# print(c_w)
cover_s = L2NormSquare(model[["mu_s"]] - P_A %*% mu2) / n2 / model[["r_s"]]^2 * c_s
cover_w = L2NormSquare(model[["mu_w"]] - P_perp %*% mu2) / n2 / model[["r_w"]]^2 * c_w
r_s_raw = model[['r_s']] / sqrt(c_s)
r_w_raw = model[['r_w']] / sqrt(c_w)
}
covered = (t(part1) %*% part2 %*% part1)/ n2 <= 1
list(r_s = model[['r_s']], r_w = model[['r_w']], k = model[['k']],
hsigma = model[['hsigma']], logVol = model[['logVol']], coverage = covered,
cover_s = cover_s, cover_w = cover_w,
diff_s_norm = diff_s_norm, diff_w_norm = diff_w_norm,
r_s_raw = r_s_raw, r_w_raw = r_w_raw,
w_norm = w_norm)
}
adaptive_real = function(X1, X2, Y1, Y2, mu1, mu2, sig) {
# constants
alpha = 0.05
# lam1 setup
lam1 = cv.glmnet(X1, Y1, intercept = F)$lambda.1se
adaptive(X1, Y1, X2, Y2, mu2, lam1, sig, alpha)
}
# read data
data("riboflavin")
x = riboflavin$x
y = riboflavin$y
# clustering
dist = as.dist(1 - abs(cor(t(x))))
model = hclust(dist)
den = as.dendrogram(model)
plot(den, horiz = T, leaflab  = 'none', xlab = expression(paste("1-|", rho, "|")))
sub_grp = cutree(model, k = 2)
table(sub_grp)
library(glmnet)
# set.seed(42)
# fit.cv <- cv.glmnet(x = x, y = y)
# b <- as.matrix(coef(fit.cv))
#
# rownames(b)[b != 0]
# sum(b != 0)
source("two_step_fun_real_data.R")
x = colScale(x)
y = y - mean(y)
X1 = x[sub_grp == 1, ]
Y1 = matrix(y[sub_grp == 1], ncol = 1)
X2 = x[sub_grp == 2, ]
Y2 = matrix(y[sub_grp == 2], ncol = 1)
# normalize X and y
x = colScale(x)
y = y - mean(y)
sig = scalreg(x, y, LSE = T)$lse$hsigma
n = length(y)
source("two_step_fun_real_data.R")
# generate data
rep_int = 10
row = rep(1:n, rep_int)
X_large = x[row, ]
mu_large = matrix(y[row], ncol = 1)
# output
tot = 1
stein1 = list()
stein2 = list()
adapt1 = list()
adapt2 = list()
for (i in 1:tot){
# index = which(sub_grp == 1)
index = sample(1:n, ceiling(n / 2))
index = rowSums(expand.grid(index, (0:(rep_int - 1)) * n))
# generate data
Y_large = mu_large + matrix(sig * rnorm(n * rep_int), ncol = 1)
X1 = X_large[index, ]
X2 = X_large[-index, ]
Y1 = Y_large[index, ,drop=F]
Y2 = Y_large[-index, ,drop=F]
mu1 = mu_large[index, ,drop=F]
mu2 = mu_large[-index, ,drop=F]
adapt1[[i]] = adaptive_real(X1, X2, Y1, Y2, mu1, mu2, sig)
adapt2[[i]] = adaptive_real(X2, X1, Y2, Y1, mu2, mu1, sig)
stein1[[i]] = two_step_stein_real_data(X1, X2, Y1, Y2, mu1, mu2, sig)
stein2[[i]] = two_step_stein_real_data(X2, X1, Y2, Y1, mu2, mu1, sig)
}
adapt_df1 = ldply(adapt1, data.frame)
adapt_df2 = ldply(adapt2, data.frame)
stein_df1 = ldply(stein1, data.frame)
stein_df2 = ldply(stein2, data.frame)
stein_df1
row
n
X_large
